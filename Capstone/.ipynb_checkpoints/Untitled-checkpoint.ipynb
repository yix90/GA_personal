{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBTI (Redo)\n",
    "\n",
    "### What happened:\n",
    "\n",
    "The previous project was \\*kind of\\* successful, except that it has a few major problems:\n",
    "\n",
    "1. It was optimized for forum postings, as per the dataset provided. Actual textual data comes in so many forms as I realised. Training becomes a hassle when inputting text data (successively!). And also, messaging data tends to be a lot shorter than forum data!\n",
    "\n",
    "2. The training set only contained forum data. This will cause bias to happen where any text data will be treated as forum text. Incidentally I managed to get hold of blog text data which will hopefully be a lot more helpful in creating a better training set.\n",
    "\n",
    "3. So far in terms of word processing I have only ran Parts of Speech and TF-IDF, and these are merely plug and play techniques. Part of the problem with mere tfidf in particular is the treatment of words as individuals, regardless of variation and spelling differences. I have not done word embeddings nor have I done any other modelling, not to mention deep learning. This shall be the chance to rectify that.\n",
    "\n",
    "4. As much as I wanted to launch my webapp onto heroku and develop the Telegram app, I have to settle the previous few points as mentioned in order to create a better trained model in order to have a better representation, then only can I launch the machine learning component for real. Luckily the skeleton for the app is done already, just need to re-train the model to launch it for real.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "1. In the 'MBTI_2nd_edition' notebook, I shall attempt to do semi-supervised modelling to find the missing target values. Namely, the S/N and T/F values which are 50% missing each.\n",
    "\n",
    "2. 'Re-do' the 1st_edition portion to analyse features with reference to the whole chunk of input instead of doing it 'per post'. This time we can also use the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving for reference\n",
    "#String for finding full sentences: [\"']?[A-Z][^.?!]+((?![.?!]['\"]?\\\\s[\"']?[A-Z][^.?!]).)+[.?!'\"]+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
